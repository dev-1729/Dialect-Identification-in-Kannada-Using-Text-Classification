{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas numpy scikit-learn openpyxl\n"
      ],
      "metadata": {
        "id": "zt9KCSWZGpVm"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.pipeline import Pipeline, FeatureUnion\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report\n"
      ],
      "metadata": {
        "id": "dx4mnAkQGpYJ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Custom Transformers ---\n",
        "\n",
        "class UnicodeTextCleaner(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X.apply(lambda x: re.sub(r'[^\\w\\s\\u0C80-\\u0CFF]', '', str(x).lower()))  # Kannada unicode range\n",
        "\n",
        "class TextStats(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return pd.DataFrame({\n",
        "            'char_count': X.apply(len),\n",
        "            'word_count': X.apply(lambda x: len(x.split())),\n",
        "            'sentence_count': X.apply(lambda x: len(re.findall(r'[.!?]+', x))),\n",
        "        })\n",
        "\n",
        "class PunctuationStats(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return pd.DataFrame({\n",
        "            'exclamation_count': X.apply(lambda x: x.count('!')),\n",
        "            'question_count': X.apply(lambda x: x.count('?')),\n",
        "            'comma_count': X.apply(lambda x: x.count(',')),\n",
        "            'period_count': X.apply(lambda x: x.count('.')),\n",
        "        })\n",
        "\n",
        "class WordLengthStats(BaseEstimator, TransformerMixin):\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return pd.DataFrame({\n",
        "            'avg_word_length': X.apply(lambda x: np.mean([len(word) for word in x.split()]) if x.split() else 0)\n",
        "        })"
      ],
      "metadata": {
        "id": "5KkLjyTRGpan"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Load your data (you can upload to Colab or use files.upload) ---\n",
        "\n",
        "# Assuming the file is named data.xlsx\n",
        "df = pd.read_excel(\"data 1.xlsx\").dropna()\n",
        "X = df['text']\n",
        "y = df['dialect']"
      ],
      "metadata": {
        "id": "6XAjBtpeGpc3"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train/Test Split ---\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n"
      ],
      "metadata": {
        "id": "GdlHzsT_Gpfl"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Feature Engineering ---\n",
        "\n",
        "combined_features = FeatureUnion([\n",
        "    ('tfidf', Pipeline([\n",
        "        ('cleaner', UnicodeTextCleaner()),\n",
        "        ('tfidf_vectorizer', TfidfVectorizer(ngram_range=(1, 2), max_features=5000))\n",
        "    ])),\n",
        "    ('stats', Pipeline([\n",
        "        ('cleaner', UnicodeTextCleaner()),\n",
        "        ('stats_union', FeatureUnion([\n",
        "            ('text_stats', TextStats()),\n",
        "            ('punctuation_stats', PunctuationStats()),\n",
        "            ('word_length_stats', WordLengthStats())\n",
        "        ]))\n",
        "    ]))\n",
        "])\n"
      ],
      "metadata": {
        "id": "3QBli6kWGpi8"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Full Pipeline ---\n",
        "pipeline = Pipeline([\n",
        "    ('features', combined_features),\n",
        "    ('classifier', RandomForestClassifier(class_weight='balanced', random_state=42, n_estimators=150))\n",
        "])"
      ],
      "metadata": {
        "id": "BS4Y1IvIHSmv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Train Model ---\n",
        "pipeline.fit(X_train, y_train)\n",
        "y_pred = pipeline.predict(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYvwxCJsHSpU",
        "outputId": "71236971-873f-4c4d-d6f4-2d8a7e486b2f"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/pipeline.py:62: FutureWarning: This Pipeline instance is not fitted yet. Call 'fit' with appropriate arguments before using other methods such as transform, predict, etc. This will raise an error in 1.8 instead of the current warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Evaluation ---\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPIvKUclHSre",
        "outputId": "a6aeee5b-53ac-42d5-e36d-0eed538d128b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            " Arre bhashe       0.88      0.81      0.84       181\n",
            "     kannada       0.93      0.96      0.94       468\n",
            "\n",
            "    accuracy                           0.92       649\n",
            "   macro avg       0.90      0.88      0.89       649\n",
            "weighted avg       0.91      0.92      0.91       649\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optional: Predict on new samples ---\n",
        "test_samples = [\n",
        "    (\"Arre bhashe\", \"ಅಭುಟ್ಟ ಎಂದೆಕೆ ಬರ್ಪಿನಿ?\"),\n",
        "    (\"kannada\", \"ಈ ಬಾರಿ ಚುನಾವಣೆಯಲ್ಲಿ ಜನತೆ ಉತ್ತಮ ನಿರ್ಧಾರ ತೆಗೆದುಕೊಳ್ಳಬೇಕಾಗಿದೆ.\"),\n",
        "]\n",
        "texts = [text for label, text in test_samples]\n",
        "true_labels = [label for label, text in test_samples]\n",
        "\n",
        "texts_series = pd.Series(texts)\n",
        "predicted_labels = pipeline.predict(texts_series)\n"
      ],
      "metadata": {
        "id": "0QQGAvQkHSt2"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show predictions\n",
        "results_df = pd.DataFrame({\n",
        "    \"Text\": texts,\n",
        "    \"True Label\": true_labels,\n",
        "    \"Predicted Label\": predicted_labels\n",
        "})"
      ],
      "metadata": {
        "id": "28vGB0r1HSxM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tabulate import tabulate\n",
        "print(tabulate(results_df, headers='keys', tablefmt='grid', showindex=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxKmYvcSHlN8",
        "outputId": "6a5bfa74-5070-44be-c8aa-6f464a4cef91"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------------------------------+--------------+-------------------+\n",
            "| Text                                   | True Label   | Predicted Label   |\n",
            "+========================================+==============+===================+\n",
            "| ಅಭುಟ್ಟ ಎಂದೆಕೆ ಬರ್ಪಿನಿ?                         | Arre bhashe  | Arre bhashe       |\n",
            "+----------------------------------------+--------------+-------------------+\n",
            "| ಈ ಬಾರಿ ಚುನಾವಣೆಯಲ್ಲಿ ಜನತೆ ಉತ್ತಮ ನಿರ್ಧಾರ ತೆಗೆದುಕೊಳ್ಳಬೇಕಾಗಿದೆ. | kannada      | kannada           |\n",
            "+----------------------------------------+--------------+-------------------+\n"
          ]
        }
      ]
    }
  ]
}